{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to create the desired complete database to use in the models later\n",
    "# Make extra table with mrn_csn_pairs of all patients we are currently including\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import tsfresh\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path and connection\n",
    "path_in = \"S:\\Dehydration_stroke\\Team Emerald\\Working Data\\Preprocessed\\Working\\Processed.db\"\n",
    "path_out = \"S:\\Dehydration_stroke\\Team Emerald\\Working Data\\Preprocessed\\Working\\Models.db\"\n",
    "con = sqlite3.connect(path_in)\n",
    "con_out = sqlite3.connect(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve flowsheet table\n",
    "flowsheet = pd.read_sql_query(\"SELECT * FROM FLOWSHEET\", con)\n",
    "neuro = pd.read_sql_query('SELECT * FROM NEURO', con)\n",
    "flowsheet = flowsheet.drop(['mrn', 'csn'], axis = 1).dropna()\n",
    "neuro = neuro.drop(['mrn', 'csn'], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append neuro data so we get all timeseries in one place\n",
    "flowsheet = flowsheet.append(neuro, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to actual datetime for manipulation and sort by key pair and then datetime\n",
    "flowsheet.loc[:, 'recorded_datetime'] = pd.to_datetime(flowsheet.loc[:, 'recorded_datetime'])\n",
    "flowsheet = flowsheet.sort_values(['mrn_csn_pair', 'recorded_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique patitents so we can pull first 24 hours of data\n",
    "pats = flowsheet.sort_values('mrn_csn_pair')['mrn_csn_pair'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.DataFrame()\n",
    "# Pull first 24 hours of data, takes a bit to run\n",
    "for i in pats:\n",
    "    temp = flowsheet[flowsheet['mrn_csn_pair'] == i]\n",
    "    # Create mast with 24 hour filter\n",
    "    mask = (temp['recorded_datetime'] >= temp['recorded_datetime'].reset_index(drop=True)[0]) & (temp['recorded_datetime'] < (np.datetime64(temp['recorded_datetime'].reset_index(drop=True)[0]) + np.timedelta64(24,'h')))\n",
    "    first = first.append(temp[mask], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you dont want to run the above, just pull from database\n",
    "first = pd.read_sql_query(\"SELECT * FROM flowsheet_first24h\", con_out)\n",
    "pats = first['mrn_csn_pair'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:50<00:00,  1.69s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:44<00:00,  1.48s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:47<00:00,  1.58s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:40<00:00,  1.36s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:48<00:00,  1.62s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:54<00:00,  1.81s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:45<00:00,  1.51s/it]\n",
      "Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 30/30 [00:46<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# Have to break dataset up to avoid memory issues, takes ~5 min to run\n",
    "extracted_flowsheet = pd.DataFrame()\n",
    "for i in range(8):\n",
    "    split1 = int(pats.shape[0] / 8) * i\n",
    "    split2 = int(pats.shape[0] / 8) * (i + 1)\n",
    "    key1 = pats[split1]\n",
    "    key2 = pats[split2]\n",
    "    index1 = first[first['mrn_csn_pair'] == key1].index[0]\n",
    "    index2 = first[first['mrn_csn_pair'] == key2].index[0] - 1\n",
    "    if i == 7:\n",
    "        index2 = first.shape[0] - 1\n",
    "    temp = first.loc[index1 : index2, :]\n",
    "    extracted_temp = tsfresh.extract_features(temp, column_id='mrn_csn_pair', column_sort='recorded_datetime', column_kind='Name', column_value='value', n_jobs=6)\n",
    "    extracted_flowsheet = extracted_flowsheet.append(extracted_temp, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_flowsheet.insert(0, 'mrn_csn_pair', pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first.to_sql('flowsheet_first24h', con_out, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uhh..have to save to excel because sql reallllyyy hates lots of columns.\n",
    "extracted_flowsheet.to_csv('extracted_flowsheet_first24h.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-dc99707ac545>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcon\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mcon_out\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'con' is not defined"
     ]
    }
   ],
   "source": [
    "con.close()\n",
    "con_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}