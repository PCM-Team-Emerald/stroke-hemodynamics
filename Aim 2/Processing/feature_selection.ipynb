{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import tsfresh\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path and connection\n",
    "path_in = \"S:\\Dehydration_stroke\\Team Emerald\\Working Data\\Preprocessed\\Working\\Processed.db\"\n",
    "path_out = \"S:\\Dehydration_stroke\\Team Emerald\\Working Data\\Preprocessed\\Working\\Models.db\"\n",
    "con = sqlite3.connect(path_in)\n",
    "con_out = sqlite3.connect(path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load in extracted timeseries data\n",
    "df = pd.read_csv('extracted_flowsheet_first24h.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sql data\n",
    "adt = pd.read_sql_query(\"SELECT * FROM ADT\", con)\n",
    "hx = pd.read_sql_query(\"SELECT * FROM HX\", con)\n",
    "dx = pd.read_sql_query(\"SELECT * FROM DX\", con)\n",
    "dem = pd.read_sql_query(\"SELECT * FROM DEMOGRAPHICS\", con)\n",
    "lda = pd.read_sql_query(\"SELECT * FROM LDA\", con)\n",
    "patients = pd.read_sql_query(\"SELECT * FROM mrn_csn_pairs\", con)\n",
    "outcome = pd.read_sql_query(\"SELECT * FROM primary_outcome\", con_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at only relevant patients\n",
    "df = df[df['mrn_csn_pair'].isin(patients['mrn_csn_pair'])]\n",
    "adt = adt[adt['mrn_csn_pair'].isin(patients['mrn_csn_pair'])]\n",
    "hx = hx[hx['mrn_csn_pair'].isin(patients['mrn_csn_pair'])]\n",
    "dx = dx[dx['mrn_csn_pair'].isin(patients['mrn_csn_pair'])]\n",
    "dem = dem[dem['mrn_csn_pair'].isin(patients['mrn_csn_pair'])]\n",
    "lda = lda[lda['mrn_csn_pair'].isin(patients['mrn_csn_pair'])]\n",
    "outcome = outcome[outcome['mrn_csn_pair'].isin(patients['mrn_csn_pair'])].reset_index(drop=True)[['mrn_csn_pair', 'LOS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = adt.drop('index', axis=1).sort_values('mrn_csn_pair', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this for now to get correct size, in future might want to use cumulative count? Might have clinical significance\n",
    "dx = dx.drop_duplicates('mrn_csn_pair').drop('index', axis=1)\n",
    "dx = dx.sort_values('mrn_csn_pair', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all patients that are not in the hx data\n",
    "temp = pd.DataFrame({'mrn_csn_pair': patients[~(patients['mrn_csn_pair'].isin(hx['mrn_csn_pair']))]['mrn_csn_pair']})\n",
    "# Add them to the dataframe with all 0s\n",
    "hx = hx.append(temp).fillna(0).drop('index', axis=1).sort_values('mrn_csn_pair')\n",
    "# If no other conditions, put 1 in none col..coulda done this the easy way but whatever\n",
    "hx['None'] = hx.drop('mrn_csn_pair', axis=1).sum(axis=1).eq(0).astype(int)\n",
    "hx = hx.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think there was 1 re-admittance? Or some kind of error? We'll just keep the first admittance for now\n",
    "dem = dem.drop(['admission_datetime', 'discharge_datetime', 'time_in_hospital_minutes'], axis=1)\n",
    "dem = dem.drop_duplicates('mrn_csn_pair').drop('index', axis=1)\n",
    "dem = dem.sort_values('mrn_csn_pair', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all patients that are not in the lda data\n",
    "temp = pd.DataFrame({'mrn_csn_pair': patients[~(patients['mrn_csn_pair'].isin(lda['mrn_csn_pair']))]['mrn_csn_pair']})\n",
    "# Add them to the dataframe with all 0s\n",
    "lda =lda.append(temp).fillna(0).drop('index', axis=1).sort_values('mrn_csn_pair')\n",
    "# If no other conditions, put 1 in none col..coulda done this the easy way but whatever\n",
    "lda['None'] = lda.drop('mrn_csn_pair', axis=1).sum(axis=1).eq(0).astype(int)\n",
    "lda = lda.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns that are completely NaN.\n",
    "df = df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([adt, hx, dx, dem, lda], axis=1)\n",
    "df2 = df2.drop('mrn_csn_pair', axis=1)\n",
    "del adt, hx, dx, dem, lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.from_pandas(df, npartitions=8)\n",
    "ddf2 = dd.from_pandas(df2, npartitions=1)\n",
    "del df, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with dask so we dont get memory errors\n",
    "ddf = ddf.join(ddf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn back into pandas\n",
    "df = ddf.compute()\n",
    "del ddf, ddf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to temp storage in case things crash\n",
    "df.to_csv('complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kinda arbirtarily drop things so we have no N/A...will need to refine this for sure\n",
    "dropped = df.dropna(axis=1, thresh=1200).dropna(axis=0, thresh=3000).dropna(axis=1)\n",
    "dropped = dropped.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last ~50 values as they are not in the flowsheet data\n",
    "dropped_temp = dropped.iloc[:, :2040]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match outcome variables\n",
    "outcome_var = outcome[outcome['mrn_csn_pair'].isin(dropped['mrn_csn_pair'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = outcome_var.reset_index(drop=True)['LOS']\n",
    "dropped_temp = dropped_temp.drop('mrn_csn_pair', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do tsfresh feature filtering\n",
    "feature_table = tsfresh.feature_selection.relevance.calculate_relevance_table(dropped_temp, outcome_var, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = pd.concat([dropped_temp.loc[:, feature_table['relevant']], dropped.iloc[:, 2041:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete.to_csv(\"S:\\Dehydration_stroke\\Team Emerald\\Working Data\\Preprocessed\\Working\\Complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()\n",
    "con_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
